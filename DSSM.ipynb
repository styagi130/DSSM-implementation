{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils.fileIterator import fileIterator\n",
    "from utils.tokenizer import wordPieceTokenizer\n",
    "from utils.funcTrackers import trackFunctionCall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trackFunctionCall\n",
    "def getTokenizer(tokenizerFilepath:pathlib.Path,newTokenizer=False):\n",
    "    if not newTokenizer:\n",
    "        with tokenizerFilepath.open(\"rb\") as pickleDumpFile:\n",
    "            return pickle.load(pickleDumpFile)\n",
    "        \n",
    "    with open(\"datafiles/DSSM/vocab_Q.wl\") as vocabFile:\n",
    "        wordInpVocab = vocabFile.read().strip().split(\"\\n\")\n",
    "    with open(\"datafiles/DSSM/vocab_A.wl\") as vocabFile:\n",
    "        wordOutVocab = vocabFile.read().strip().split(\"\\n\")\n",
    "\n",
    "    tokenizer = wordPieceTokenizer(wordInpVocab,wordOutVocab)\n",
    "\n",
    "    with open(\"tokenizerIndexer.pkl\",\"wb\") as pickleDumpFile:\n",
    "        pickle.dump(tokenizer,pickleDumpFile,pickle.HIGHEST_PROTOCOL)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trackFunctionCall\n",
    "def getGroupedData(dataFrame,toGroup):\n",
    "    groupedDf = dataFrame.groupby(toGroup).groups\n",
    "    newDf     = pd.DataFrame(columns=[\"inpSeq\",\"outSeq\"])\n",
    "    dfRowsLen = newDf.shape[0]\n",
    "    for sentencePairTag in groupedDf.keys():\n",
    "        sentencePairIndexes   = groupedDf[sentencePairTag]\n",
    "        subDf                 = dataFrame.loc[sentencePairIndexes]\n",
    "        inpSeq                = \" \".join(subDf[\"inpSeq\"]).strip()\n",
    "        outSeq                = \" \".join(subDf[\"outSeq\"]).strip()\n",
    "        newDf.loc[dfRowsLen]  = [inpSeq,outSeq]\n",
    "        dfRowsLen            += 1\n",
    "    return newDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trackFunctionCall\n",
    "def convertCtf2Csv(filename:pathlib.Path):\n",
    "    dataFrame = pd.read_csv(str(filename.resolve()),delimiter=\"|\",header=None,names=[\"pairTag\",\"inpSeq\",\"outSeq\"])\n",
    "    dataFrame[\"inpSeq\"].fillna(\"S0 \\t:1\\t\",inplace=True)\n",
    "    dataFrame[\"outSeq\"].fillna(\"S1 \\t:1\"  ,inplace=True)\n",
    "    \n",
    "    funcToRemoveTags = lambda x:x.split(\" \")[-1].split(\":\")[0]\n",
    "    dataFrame[\"inpSeq\"] = dataFrame[\"inpSeq\"].apply(funcToRemoveTags)\n",
    "    dataFrame[\"outSeq\"] = dataFrame[\"outSeq\"].apply(funcToRemoveTags)\n",
    "\n",
    "    basepath     = filename.parent\n",
    "    filestem     = filename.stem\n",
    "    subFolder    = \"pytorch\"\n",
    "    parentFolder = basepath      / subFolder\n",
    "    filepath     = parentFolder / f\"{filestem}.csv\"\n",
    "    \n",
    "    cleanDfTrain = getGroupedData(dataFrame,\"pairTag\")\n",
    "    cleanDfTrain.to_csv(str(filepath.resolve()),header=False,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainDataFramePath = pathlib.Path(\"./datafiles/DSSM/train.pair.tok.ctf\")\n",
    "#validDataFramePath = pathlib.Path(\"./datafiles/DSSM/valid.pair.tok.ctf\")\n",
    "\n",
    "#convertCtf2Csv(trainDataFramePath)\n",
    "#convertCtf2Csv(validDataFramePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self,pairIterator,tokenizer):\n",
    "        self.pairIterator = pairIterator\n",
    "        self.tokenizer    = tokenizer\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        inpSeq,outSeq = self.pairIterator[index]\n",
    "        inpSeq,outSeq = self.tokenizer.tokenize(inpSeq,\"inpSeq\"),self.tokenizer.tokenize(outSeq,\"outSeq\")\n",
    "        return torch.tensor(inpSeq),torch.tensor(outSeq)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairIterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelDSSM(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Think of how we can implement attention in this!!\n",
    "    \"\"\"\n",
    "    def __init__(self,vocabSize,wordEmbeddingDim,hiddenStateDim,sentenceVecDim,fc1Dim,dropout1=0.5,dropout2=0.5,numRnnLayers=1,bidirectional=True,batchFirst=True,debug=True):\n",
    "        super(modelDSSM,self).__init__()\n",
    "        self.debug              = debug\n",
    "        self.wordEmbeddingDim   = wordEmbeddingDim\n",
    "        self.vocabSize          = vocabSize\n",
    "        self.sentenceVecDim     = sentenceVecDim\n",
    "        \n",
    "        self.hiddenStateDim     = hiddenStateDim\n",
    "        self.numRnnLayers       = numRnnLayers\n",
    "        self.bidirectional      = bidirectional\n",
    "        self.batchFirst         = batchFirst\n",
    "        self.directions         = 2 if self.bidirectional else 1\n",
    "        self.initHidenStateVar  = self.numRnnLayers*self.directions #Used in initializing hidden states\n",
    "        \n",
    "        self.fc1Dim             = fc1Dim\n",
    "        self.fc1InpDim          = self.hiddenStateDim*self.directions\n",
    "\n",
    "        self.dropOut1Th         = dropout1\n",
    "        self.dropOut2Th         = dropout2\n",
    "        \n",
    "        self.wordPieceEmbedding = torch.nn.Embedding(self.vocabSize,self.wordEmbeddingDim)\n",
    "        self.rnn                = torch.nn.GRU(self.wordEmbeddingDim,self.hiddenStateDim,num_layers=self.numRnnLayers,bidirectional=self.bidirectional,batch_first=self.batchFirst)\n",
    "        \n",
    "        self.fc1                = torch.nn.Linear(self.fc1InpDim,self.fc1Dim)\n",
    "        self.fc2                = torch.nn.Linear(self.fc1Dim,self.sentenceVecDim)\n",
    "        \n",
    "        self.dropOut1           = torch.nn.Dropout(self.dropOut1Th)\n",
    "        self.dropOut2           = torch.nn.Dropout(self.dropOut2Th)\n",
    "        \n",
    "    def forward(self,input,rnnInitialHiddenStates):\n",
    "        # Compute token embeddings(Wordpiece in this case)\n",
    "        wordPieceEmbeddings = self.wordPieceEmbedding(input)\n",
    "        wordPieceEmbeddings = self.dropOut1(wordPieceEmbeddings)\n",
    "        self.printTensorShape(\"Wordpiece embeddings\",wordPieceEmbeddings)\n",
    "\n",
    "        # Calculate RNN Outputs\n",
    "        rnnOutputs,_        = self.rnn(wordPieceEmbeddings,rnnInitialHiddenStates)\n",
    "        self.printTensorShape(\"RNN\",rnnOutputs)\n",
    "        \n",
    "        # Compute FC1 outputs and apply relu activation and dropout\n",
    "        fc1Inpts            = rnnOutputs[:,-1,:]\n",
    "        fc1Outputs          = self.fc1(fc1Inpts)\n",
    "        fc1Outputs          = torch.nn.functional.relu(fc1Outputs)\n",
    "        fc1Outputs          = self.dropOut2(fc1Outputs)\n",
    "        self.printTensorShape(\"Fully Connected1\",fc1Outputs)\n",
    "\n",
    "        # Compute sentenceVectors and apply tanh activation\n",
    "        sentenceEmbeddings  = self.fc2(fc1Outputs)\n",
    "        sentenceEmbeddings  = torch.nn.functional.tanh(sentenceEmbeddings)\n",
    "        self.printTensorShape(\"Final sentence embeddings\",sentenceEmbeddings)\n",
    "        \n",
    "        return sentenceEmbeddings\n",
    "        \n",
    "        \n",
    "    def printTensorShape(self,layer,tensorUnderObservation):\n",
    "        if self.debug:\n",
    "            print(f\"{layer} output shapes is: {tensorUnderObservation.shape}\")\n",
    "\n",
    "    def initHidden(self,batchSize):\n",
    "        hiddenStateShape = (self.initHidenStateVar,batchSize,self.hiddenStateDim)\n",
    "        if self.debug:\n",
    "            print (f\"initial hidden dimension shape is: {hiddenStateShape}\")\n",
    "        return torch.normal(0,0.5,size=hiddenStateShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a call to function: getTokenizer\n",
      "Finished executing function: getTokenizer in 0.007960111999636865 seconds\n"
     ]
    }
   ],
   "source": [
    "tokenizer     = getTokenizer(pathlib.Path(\"./tokenizerIndexer.pkl\"),newTokenizer=True)\n",
    "dataParams    = {\n",
    "                    \"shuffle\"   : True,\n",
    "                    \"batch_size\" : 1\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIterator    = fileIterator(pathlib.Path(\"datafiles/DSSM/pytorch/train.pair.tok.csv\"),tokenize=False)\n",
    "valIterator      = fileIterator(pathlib.Path(\"datafiles/DSSM/pytorch/valid.pair.tok.csv\"),tokenize=False)\n",
    "   \n",
    "trainDataIter    = dataSet(trainIterator,tokenizer)\n",
    "valDataIter      = dataSet(valIterator,tokenizer)\n",
    "\n",
    "dataLoaders      = {\n",
    "                    \"train\" : torch.utils.data.DataLoader(trainDataIter,**dataParams),\n",
    "                    \"val\"   : torch.utils.data.DataLoader(valDataIter,**dataParams)\n",
    "                   }\n",
    "dataLoadersLens  = {\n",
    "                    \"train\" : len(trainDataIter),\n",
    "                    \"val\"   : len(valDataIter)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noZeroDivision(dividend,divisor,rounOffVal):\n",
    "    try:\n",
    "        return round(dividend/divisor,rounOffVal)\n",
    "    except ZeroDivisionError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trackFunctionCall\n",
    "def train(model,optimizer,criterion,phaseList,numStepsBeforeVal,dataLoaders,dataLoadersLen,epochs=1):\n",
    "    phaseLossDict = {\"train\":[],\"val\":[]}\n",
    "    stepLossDict  = {\"train\":[],\"val\":[]}\n",
    "    for batchedEpoch in range(0,epochs,numStepsBeforeVal):\n",
    "        for subEpochCounter, phase in enumerate(phaseList,start=1):\n",
    "            if phase==\"train\":\n",
    "                model.train()\n",
    "            if phase==\"val\":\n",
    "                model.eval()\n",
    "            phaseLoss = 0\n",
    "            for step,(inpSeq,outSeq) in enumerate(dataLoaders[phase]):                \n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    \n",
    "                    if phase==\"train\":\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                    inpSeq = inpSeq.to(device)\n",
    "                    outSeq = outSeq.to(device)\n",
    "                    target = torch.ones(model.sentenceVecDim).to(device)\n",
    "\n",
    "                    initialHiddenStates = model.initHidden(dataParams[\"batch_size\"]).to(device)\n",
    "                    sentVectInp = model(inpSeq,initialHiddenStates)\n",
    "\n",
    "                    initialHiddenStates = model.initHidden(dataParams[\"batch_size\"]).to(device)\n",
    "                    sentVectOut = model(outSeq,initialHiddenStates)\n",
    "                    loss        = criterion(sentVectInp,sentVectOut,target)\n",
    "                    stepLoss    = loss.item()\n",
    "                    phaseLoss  += stepLoss\n",
    "                    stepLossDict[phase].append(stepLoss)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            totalLoss = noZeroDivision(phaseLoss,dataLoadersLen[phase],6)\n",
    "            phaseLossDict[phase].append(totalLoss)\n",
    "            print (f\"Phase:{phase} --- Step: {batchedEpoch+subEpochCounter} --- epoch loss: {totalLoss}\")\n",
    "    return model,phaseLossDict,stepLossDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabSize          = len(tokenizer.wordPieceMeta[\"vocab\"])\n",
    "wordEmbeddingDim   = 300\n",
    "hiddenStateDim     = 512\n",
    "sentenceVecDim     = 150\n",
    "fc1Dim             = 256\n",
    "\n",
    "numStepsBeforeVal  = 25\n",
    "phaseList          = [*[\"train\"]*numStepsBeforeVal,\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dssmModel          = modelDSSM(vocabSize,wordEmbeddingDim,hiddenStateDim,sentenceVecDim,fc1Dim,debug=False).to(device)\n",
    "criterion          = torch.nn.CosineEmbeddingLoss(margin=0.5)\n",
    "optimizer          = torch.optim.RMSprop(dssmModel.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making a call to function: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwantics/anaconda3/envs/torch1_2/lib/python3.8/site-packages/torch/nn/functional.py:1558: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase:train --- Step: 1 --- epoch loss: 0.015527\n",
      "Phase:train --- Step: 2 --- epoch loss: 0.0\n",
      "Phase:train --- Step: 3 --- epoch loss: 0.0\n",
      "Phase:train --- Step: 4 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 5 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 6 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 7 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 8 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 9 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 10 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 11 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 12 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 13 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 14 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 15 --- epoch loss: 0.0\n",
      "Phase:train --- Step: 16 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 17 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 18 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 19 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 20 --- epoch loss: 0.0\n",
      "Phase:train --- Step: 21 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 22 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 23 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 24 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 25 --- epoch loss: -0.0\n",
      "Phase:val --- Step: 26 --- epoch loss: 0.0\n",
      "Phase:train --- Step: 26 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 27 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 28 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 29 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 30 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 31 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 32 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 33 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 34 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 35 --- epoch loss: 0.0\n",
      "Phase:train --- Step: 36 --- epoch loss: 0.0\n",
      "Phase:train --- Step: 37 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 38 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 39 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 40 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 41 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 42 --- epoch loss: -0.0\n",
      "Phase:train --- Step: 43 --- epoch loss: -0.0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ada9ab4b9c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdssmModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphaseLossDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstepLossDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdssmModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphaseList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumStepsBeforeVal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataLoaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataLoadersLens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/python3-tasks/selfStudy/edxNLP/dssm/utils/funcTrackers.py\u001b[0m in \u001b[0;36mwrapperFunc\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Making a call to function: {func.__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mfunctionReturns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mendTime\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Finished executing function: {func.__name__} in {endTime-startTime} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e119e71196f1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, phaseList, numStepsBeforeVal, dataLoaders, dataLoadersLen, epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0msentVectOut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutSeq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitialHiddenStates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mloss\u001b[0m        \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentVectInp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msentVectOut\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mstepLoss\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0mphaseLoss\u001b[0m  \u001b[0;34m+=\u001b[0m \u001b[0mstepLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0mstepLossDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstepLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure"
     ]
    }
   ],
   "source": [
    "dssmModel,phaseLossDict,stepLossDict = train(dssmModel,optimizer,criterion,phaseList,numStepsBeforeVal,dataLoaders,dataLoadersLens,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (torch1_2)",
   "language": "python",
   "name": "torch1_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
